{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop DAGA 2024\n",
    "\n",
    "The **Py**thon package **f**or **A**coustics **R**esearch (pyfar) contains classes and functions for the acquisition, inspection, and processing of audio signals.\n",
    "\n",
    "Pyfar is developed with a strong focus on:\n",
    "\n",
    "- **Online documentation**.\n",
    "- **Automated testing**.\n",
    "- Unrestricted use through the liberal MIT or CC-BY **open source** licenses.\n",
    "\n",
    "For ease of maintainability and robustness to future changes, applied or specific features are split into sub-packages which extend the base package.\n",
    "\n",
    "These currently include:\n",
    "\n",
    "- **sofar**: SOFA file reader and writer functionality.\n",
    "- **spharpy**: Spherical array signal processing.\n",
    "- **pyrato**: Tools for room acoustic analysis.\n",
    "\n",
    "Please refer to [pyfar.org](https://pyfar.org) For a up-to-date list of packages and their intended use cases\n",
    "\n",
    "We develop all packages openly across diverse research institutions, avoiding general branding of code or functionality. Contributions (in any form, i.e. reporting issues, submitting bug-fixes or implementation of new features) are welcome. \n",
    "To get in touch, either contact us via\n",
    "\n",
    "- [GitHub](https://github.com/pyfar).\n",
    "- [Join the Slack channel](https://join.slack.com/t/pyfar/shared_invite/zt-2eacdhww2-iUiPnh_wuqg2zD939wL4kw).\n",
    "- Write an old-school E-Mail to info@pyfar.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Gallery\n",
    "\n",
    "This notebook, among others, is part of [pyfar's example gallery](https://pyfar-gallery.readthedocs.io/en/latest/).\n",
    "The gallery contains:\n",
    "\n",
    "- Notebooks supplementary to the [documentation](https://pyfar.readthedocs.io/en/latest).\n",
    "- Application examples giving an overview over the use cases pyfar and its sub-packages.\n",
    "\n",
    "All examples can either be \n",
    "\n",
    "- viewed as statically rendered web-pages,\n",
    "- interactively executed on mybinder.org,\n",
    "- downloaded and run locally.\n",
    "\n",
    "The respective links are located at the top of each example notebook. \n",
    "\n",
    "To follow along with the workshop document, either navigate to [pyfar.org](https://pyfar.org) and scroll down to the **Workshop DAGA 2024** example, or scan the following QR code:\n",
    "\n",
    "`I'm a little happy placeholder. When I'm grown up I'll be a QR code.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### _Disclaimer_:\n",
    "Please note that this is not a Python tutorial. We assume that you are aware of basic Python coding and concepts. For installations or set-up instructions please refer to the [getting started section of the documentation](https://pyfar.readthedocs.io/en/latest/readme.html#getting-started)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pyfar as pf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set matplotlib backend for plotting\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating audio data\n",
    "\n",
    "Audio data are the basis of pyfar and most data will be stored `Signal` objects. Signals are intended for equally sampeled time and frequency data. Examples for this are audio recordings, impulse responses, or single sided spectra between 0 Hz and half the sampling rate. pyfar also defines `TimeData` and `FrequencyData` objects that are intended to store incomplete audio data. A more detail introduction to pyfar audio objects can be found [here](https://pyfar-gallery.readthedocs.io/en/latest/gallery/interactive/pyfar_audio_objects.html). \n",
    "\n",
    "*Signals* can be created in different ways. Custom data can be entered in the form of numpy arrays as the following example of creating an impulse signal with a sampling rate of 44100 Hz shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(6)\n",
    "x[0] = 1\n",
    "impulse = pf.Signal(x, 44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the time data in the *Signal* object with the `time` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impulse.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the frequency data with the `freq` attribute. This will automatically compute the frequency data inside the *Signal* object using the Fast Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impulse.freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An impulse is a common audio signal and pyfar contains functions for creating for example sine signals, sweeps, and noise signals. These function are located in the [`pyfar.signals`](https://pyfar.readthedocs.io/en/stable/modules/pyfar.signals.html) module. An identical dirac signal can be created with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impulse = pf.signals.impulse(6)\n",
    "impulse.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other cases it might be desired to have more natural signals for a quick demo of an audio system. Signals such as speech, castanets, drums, and guitar snippets are part of the [`pyfar.signals.files`](https://pyfar.readthedocs.io/en/stable/modules/pyfar.signals.files.html) module. Lets obtain a speech signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = pf.signals.files.speech()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signals are also often stored on disk and the [`pyfar.io`](https://pyfar.readthedocs.io/en/stable/modules/pyfar.io.html) module can read and write common audio file types such as *wav* and *mp3*. In addition it can also import *sofa* files and data simulated with Comsol. This is how to load a room impulse response (RIR) from a wav-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir = pf.io.read_audio(os.path.join(\n",
    "    '..', '..', 'resources', 'impulse_response_measurement.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speech signal and the room impulse response are rather tedious to inspect by looking at the time or frequency data, because they are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to inspect longer or more complex signals is by plotting them, which is illustrated in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive plots<a class=\"anchor\" id=\"#interactive_plots\"></a>\n",
    "\n",
    "pyfar provides keyboard shortcuts for switching plots, zooming in and out, moving along the x and y axis, and for zooming and moving the range of colormaps. To do this, you need to use an interactive matplotlib backend. \n",
    "These can be used with any interactive matplotlib backend. For jupyter notebooks one can for example use the following matplotlib magic\n",
    "\n",
    "`%matplotlib ipympl`\n",
    "\n",
    "Note that the line magic was already executed at the beginning of the notebook, since the backend can only be chosen once per notebook.\n",
    "\n",
    "A list of available shortcuts is found in the [documentation](https://pyfar.readthedocs.io/en/stable/concepts/pyfar.plot.html#interactive-plots) or by executing the following function inside an interactive interpreter session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortcuts = pf.plot.shortcuts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following figure can be used as interactive example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "ax = pf.plot.time(rir, dB=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinates<a class=\"anchor\" id=\"coordinates\"></a>\n",
    "\n",
    "The `Coordinates()` class is designed for storing, manipulating, and accessing coordinate points. It supports a large variety of different coordinate conventions and the conversion between them. Examples for data that can be stored are microphone positions of a spherical microphone array and loudspeaker positions of a sound field synthesis system. Lets create an empty `Coordinates` object. Visit the [coordinate concepts](https://pyfar.readthedocs.io/en/latest/concepts/pyfar.coordinates.html) for a graphical overview of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pf.Coordinates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entering coordinate points<a class=\"anchor\" id=\"coordinates_enter\"></a>\n",
    "\n",
    "Coordinate points can be entered manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pf.Coordinates(np.arange(-5., 6), 0, 0)\n",
    "# show general information\n",
    "print(c)\n",
    "# plot the sampling points\n",
    "c.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to initalize `Coordinate` objects is the `pf.Coordinates(x, y, z)` constructor or for other coordinate systems classmethods like `pf.Coordinates.from_spherical_elevation(azimuth, elevation, radius)`. Visit the [coordinate class](https://pyfar.readthedocs.io/en/latest/classes/pyfar.coordinates.html) for more datails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = pf.Coordinates.from_spherical_elevation([0, np.pi/2, np.pi], 0, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `Coordinates` object, the Coordinates are stored in a cartesian coordinate system for each `x`, `y` and `z`. Information about coordinate array can be obtained by `c.cshape`, `c.csize`, and `c.cdim`. These properties are similar to numpy's `shape`, `size`, and `dim` of each `x`, `y` and `z`.\n",
    "Additionally we can use available sampling schemes contained in https://spharpy.readthedocs.io/en/latest/spharpy.samplings.html."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving coordinate points<a class=\"anchor\" id=\"coordinates_retrieve\"></a>\n",
    "\n",
    "There are different ways to retrieve points from a `Coordinates` object. All points can be obtained in cartesian, spherical, and cylindrical coordinates using the related properties `c.cartesian`, `c.sperical_evaluation` and `c.cylindrical`. Also single properties of each coordinate system convention can be accessed by e.g. `c.azimuth`, `c.radius` or `c.x`. Visit the [coordinate class](https://pyfar.readthedocs.io/en/latest/classes/pyfar.coordinates.html) for more details.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_coordinates = c.cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different methods are available for obtaining a specific subset of coordinates. For example, the nearest `k` point(s) can be obtained by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = pf.Coordinates.from_spherical_colatitude(270/180*np.pi, 90/180*np.pi, 1)\n",
    "index_out, distance = c.find_nearest(find, k=1)\n",
    "c.show(index_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to find all points in a certain area around different points. Different distance measures are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = c.find_within(find, distance=3, distance_measure='euclidean')\n",
    "c.show(index_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain all points within a specified euclidean distance or arc distance, you can use `c.get_nearest_cart()` and `c.get_nearest_sph()`. To obtain more complicated subsets of any coordinate, e.g., the horizontal plane with `colatitude=90` degree, you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_out = c.colatitude == 90/180*np.pi\n",
    "c.show(index_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotating coordinates<a class=\"anchor\" id=\"coordinates_rotate\"></a>\n",
    "\n",
    "You can apply rotations using quaternions, rotation vectors/matrixes and euler angles with  `c.rotate()`, which is a wrapper for `scipy.spatial.transform.Rotation`. For example rotating around the y-axis by 45 degrees can be done with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.rotate('y', 45)\n",
    "c.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this changes the points inside the `Coordinates` object, which means that you have to be careful not to apply the rotation multiple times, i.e., when evaluationg cells during debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Measurement Based Equalization Filter\n",
    "\n",
    "## Digital Signal Processing Functions\n",
    "\n",
    "The previously introduced RIR can also be used to obtain an FIR equalization filter for the listening position.\n",
    "Typically, it is not feasible to equalize for the exact frequency response of the room, as notches and peaks are sensitive to local variations of the receiver position.\n",
    "A more sensible approach is using a smoothed magnitude spectrum for room equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = pf.plot.freq(rir, dB=True, label='Original RTF', color='grey', alpha=0.75)\n",
    "\n",
    "rir_smoothed = pf.dsp.smooth_fractional_octave(rir, 2)[0]\n",
    "ax = pf.plot.freq(rir_smoothed, dB=True, label='Smoothed RTF')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to parametric IIR filter designs, FIR equalization filter can be generated from the inverse magnitude spectrum in a straight forward manner. Due to the roll-off below 80 Hz, and above 20 kHz, regularization outside these limits is required to avoid excessive noise amplification.\n",
    "\n",
    "The inverse spectrum is calculated using a Tikhonov inverse filter.\n",
    "$$S^{-1}(f) = \\frac{S^*(f)}{S^*(f)S(f) + \\epsilon(f)}$$\n",
    "\n",
    "To not affect the inverse of the filter within the aforementioned limits, frequency limits are passed to the inversion function. Regularization inside and outside the frequency limits is supported by creating a frequency dependent regularization function $\\epsilon(f)$. Since the spectrum was already smoothed in a previous step, no regularization is applied within the frequency limits. The regularization values outside these frequency limits are chosen, such that the resulting spectrum does not show roll-offs or steep sloes, subject to ringing or long filter decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_range = [100, 18e3]\n",
    "rir_inv = pf.dsp.regularized_spectrum_inversion(rir_smoothed, frequency_range, regu_outside=5e-2)\n",
    "\n",
    "plt.figure()\n",
    "pf.plot.freq(rir_smoothed, dB=True, label='Smoothed RTF', color='grey', alpha=0.75)\n",
    "ax = pf.plot.freq(rir_inv, dB=True, label='Inverted RTF')\n",
    "ax.axvline(frequency_range[0], color='black', linestyle='--')\n",
    "ax.axvline(frequency_range[1], color='black', linestyle='--')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the fractional octave smoothing returns a zero-phase filter, the phase response needs to be reconstructed to achieve a causal filter. This can either be achieved using a linear phase, or minimum phase.\n",
    "For a time domain FIR implementation, a minimum phase filter is chosen. The reconstruction is implemented using the Hilbert transform without approximation of the magnitude spectrum.\n",
    "\n",
    "To guarantee no amplitude distortions of signals, the filter is further normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_inv = pf.dsp.normalize(rir_inv)\n",
    "rir_inv_lin_phase = pf.dsp.minimum_phase(rir_inv)\n",
    "\n",
    "plt.figure()\n",
    "pf.plot.time(rir_inv_lin_phase, dB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_inv_lin_phase_wind = pf.dsp.time_window(rir_inv_lin_phase, [900, 1023], shape='right', crop='end', unit='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pf.plot.time(rir_inv_lin_phase_wind, dB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For validation of the create equalization filter, one may convolve the it with the measured and unmodified room impulse response.\n",
    "Pyfar implements a dedicated convolution function supporting linear (time domain and Fourier transform based using the overlap-add algorithm) or cyclic convolution. \n",
    "However, the `*` operator may also be used for frequency domain multiplications; that is cyclic convolution in the time domain.\n",
    "Analogously, the `/` operator implements a frequency domain division, the `@` operator implements a frequency domain matrix multiplication, and the `**` operator is the frequency domain power operator. The `+` and `-` operators are domain agnostic.\n",
    "\n",
    "Note that using the arithmetic operators requires matching signal lengths. In the current example this would require zero-padding the newly created equalization filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applied_filter  = rir * pf.dsp.pad_zeros(rir_inv_lin_phase, rir.n_samples-rir_inv_lin_phase.n_samples)\n",
    "\n",
    "plt.figure()\n",
    "pf.plot.freq(rir, color='grey', label='Original RTF')\n",
    "ax = pf.plot.freq(applied_filter, alpha=0.7, label='Equalized RTF')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Classes\n",
    "\n",
    "Pyfar implements filters as encapsulated class objects, with similar intend as the respective Signal class objects.\n",
    "Filter objects support storing sets of coefficients for FIR, IIR, as well as second order section IIR (SOS) filters.\n",
    "They further facilitate the piece-wise processing of audio signals while storing the filter state.\n",
    "\n",
    "A filter class object storing the previously created equalization filter only requires initializing the respective FilterFIR class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_filter = pf.FilterFIR(rir_inv_lin_phase_wind.time, 44100)\n",
    "eq_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyfar provides audio examples. We choose the short anechoic guitar sample to create an example for the measured listener position, which is convolved with the room impulse response, simulating playback at the measured listener position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guitar = pf.dsp.resample(pf.signals.files.guitar(), rir.sampling_rate)\n",
    "reverberant_guitar = pf.dsp.convolve(guitar, rir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equalization filter is applied to the guitar sample using the filter objects `process` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverberant_guitar_equalized = eq_filter.process(reverberant_guitar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both audio signals can be auralized using jupyter's Audio widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "Audio(reverberant_guitar.time, rate=guitar.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(reverberant_guitar_equalized.time, rate=guitar.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyfar implements a number of digital filters with various use-cases.\n",
    "For these filters, convenience functions exist as well, combining creation and application of a filter to a signal into a single function call.\n",
    "\n",
    "The following example applies a fractional octave filter band to the room impulse response, creating a multi-channel Signal. For better visibility, use `[` and `]` to cycle through the channels inside the plot.\n",
    "\n",
    "When the plot does not respond to hotkeys, try clicking the figure to activate hotkeys for the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_fractional_octaves = pf.dsp.filter.fractional_octave_bands(rir, 1, freq_range=[250, 8e3])\n",
    "\n",
    "plt.figure()\n",
    "pf.plot.time(rir_fractional_octaves, dB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License notice\n",
    "This notebook © 2024 by [the pyfar developers](https://github.com/orgs/pyfar/people) is licensed under [CC BY 4.0](http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1)\n",
    "\n",
    "![CC BY Large](https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -iv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31fda18d23bccfca635c34b8e2ae5cca9cc1e70ba24d7dd63263c3d313ebed7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
